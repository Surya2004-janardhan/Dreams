const { generateScript } = require("../services/scriptService");
const {
  generateAudioWithBatchingStrategy,
} = require("../services/audioService");
const { generateImages } = require("../services/imageService");
const { getBaseVideo } = require("../services/videoService");
const { createSubtitlesFile } = require("../utils/subtitles");
const cleanLLMData = require("../utils/textCleaner");
const logger = require("../config/logger");
const ffmpeg = require("fluent-ffmpeg");
const fs = require("fs");
const path = require("path");

// Store current workflow state
let currentWorkflow = {
  taskId: null,
  status: "idle",
  currentStep: null,
  error: null,
  results: {},
};

// Main workflow execution
const runWorkflow = async (req, res) => {
  try {
    const { title, description } = req.body;

    if (!title) {
      return res.status(400).json({ error: "Title is required" });
    }

    // Initialize workflow
    const taskId = Date.now().toString();
    currentWorkflow = {
      taskId,
      status: "running",
      currentStep: "script/generate",
      error: null,
      results: {},
    };

    logger.info(`üöÄ Starting workflow for task: ${title}`);

    // Step 1: Generate script
    logger.info("‚Üí Step 1: Generating script");
    const prompt = `${title}. ${description || ""}`;
    const rawScript = await generateScript(prompt);
    const script = cleanLLMData.extractConversation(rawScript);

    if (!script || script.length < 100) {
      throw new Error("Generated script is too short or empty");
    }

    currentWorkflow.results.script = script;
    logger.info("‚úì Script generated");

    // Step 2: Check for existing audio files
    logger.info("‚Üí Step 2: Checking for existing audio files");
    let audioFiles;
    const existingAudioFiles = [];

    // Check for conversation audio file
    const audioPattern = "audio/conversation_*.wav";
    const audioDir = "audio";

    if (fs.existsSync(audioDir)) {
      const audioFilesList = fs.readdirSync(audioDir);
      const conversationFiles = audioFilesList.filter(
        (file) => file.startsWith("conversation_") && file.endsWith(".wav")
      );

      if (conversationFiles.length > 0) {
        const latestAudio = conversationFiles.sort().pop();
        existingAudioFiles.push({
          conversationFile: path.resolve(path.join(audioDir, latestAudio)),
        });
      }
    }

    if (existingAudioFiles.length > 0) {
      logger.info("‚úÖ Audio file already exists, skipping generation");
      logger.info("‚è© Skipping audio generation step");
      audioFiles = existingAudioFiles[0];
    } else {
      logger.info("üé§ No existing audio found, generating new audio");
      currentWorkflow.currentStep = "audio/generate";
      audioFiles = await generateAudioWithBatchingStrategy(script);
    }

    currentWorkflow.results.audioFiles = audioFiles;
    logger.info("‚úì Audio ready");

    // Step 3: Get base video from Google Drive
    logger.info("‚Üí Step 3: Getting base video");
    currentWorkflow.currentStep = "video/base";
    const baseVideoUrl = await getBaseVideo();
    currentWorkflow.results.baseVideoUrl = baseVideoUrl;
    logger.info("‚úì Base video retrieved");

    // Step 4: Check for existing images
    logger.info("‚Üí Step 4: Checking for existing images");
    let images;
    const existingImages = [];

    // Check for existing images (image_0.png to image_4.png)
    for (let i = 0; i < 5; i++) {
      const imagePath = `images/image_${i}.png`;
      if (fs.existsSync(imagePath)) {
        existingImages.push({
          index: i,
          filename: imagePath,
          prompt: `Existing image ${i}`,
        });
        logger.info(`‚úì Found existing image: ${imagePath}`);
      }
    }

    if (existingImages.length >= 5) {
      logger.info("‚úÖ All 5 images already exist, skipping generation");
      logger.info("‚è© Skipping image generation step");
      images = existingImages;
    } else {
      logger.info(
        `üñºÔ∏è Found ${existingImages.length}/5 images, generating remaining ${
          5 - existingImages.length
        }`
      );
      currentWorkflow.currentStep = "images/generate";
      images = await generateImages(script);
    }
    currentWorkflow.results.images = images;
    logger.info(`‚úì Images ready - ${images.length} images`);

    // Step 5: Assemble video
    logger.info("‚Üí Step 5: Assembling final video");
    currentWorkflow.currentStep = "video/assemble";
    const finalVideo = await assembleVideo(
      baseVideoUrl,
      images,
      audioFiles,
      script
    );
    currentWorkflow.results.finalVideo = finalVideo;
    logger.info("‚úì Video assembled");

    // Complete workflow
    currentWorkflow.status = "completed";
    currentWorkflow.currentStep = "completed";
    logger.info(`üéâ Workflow completed successfully: ${finalVideo}`);

    res.json({
      success: true,
      taskId,
      result: {
        script,
        audioFiles,
        images,
        finalVideo,
      },
    });
  } catch (error) {
    logger.error("‚ùå Workflow failed:", error.message);
    currentWorkflow.status = "error";
    currentWorkflow.error = error.message;

    res.status(500).json({
      error: "Workflow failed",
      details: error.message,
      taskId: currentWorkflow.taskId,
    });
  }
};

// Video assembly function
const assembleVideo = async (baseVideoUrl, images, audioFiles, script) => {
  const outputPath = `videos/final_${Date.now()}.mp4`;
  const subtitlesPath = `subtitles/subtitles_${Date.now()}.srt`;

  // Create SRT subtitle file
  createSubtitlesFile(script, subtitlesPath);

  // Handle base video - could be URL or local path
  let baseVideoPath = "temp/base_video.mp4";

  if (
    baseVideoUrl.startsWith("http://") ||
    baseVideoUrl.startsWith("https://")
  ) {
    logger.info(`‚Üí Downloading base video from URL: ${baseVideoUrl}`);
    // Download logic would go here
    logger.info(`‚úì Base video downloaded: ${baseVideoPath}`);
  } else {
    // It's a local file path
    logger.info(`‚Üí Using local base video: ${baseVideoUrl}`);
    baseVideoPath = baseVideoUrl;

    if (!fs.existsSync(baseVideoPath)) {
      throw new Error(`Base video file not found: ${baseVideoPath}`);
    }
  }

  // Prepare audio
  const combinedAudioPath = "temp/combined_audio.mp3";
  await combineAudioFiles(audioFiles, combinedAudioPath);

  return new Promise((resolve, reject) => {
    let command = ffmpeg(baseVideoPath)
      .input(combinedAudioPath)
      .audioCodec("aac")
      .videoCodec("libx264");

    // Add images as overlays with improved positioning and timing
    images.forEach((image, index) => {
      const startTime = index * 15; // Show each image for 15 seconds
      command = command.input(image.filename);
    });

    // Create filter complex for image overlays in upper portion
    let filterComplex = "";
    images.forEach((image, index) => {
      const inputIndex = index + 2; // +2 because input 0 is video, input 1 is audio
      const startTime = index * 15;
      const endTime = startTime + 15;

      if (index === 0) {
        filterComplex += `[0:v][${inputIndex}:v]overlay=W*0.1:H*0.1:enable='between(t,${startTime},${endTime})'[v${index}];`;
      } else {
        filterComplex += `[v${
          index - 1
        }][${inputIndex}:v]overlay=W*0.1:H*0.1:enable='between(t,${startTime},${endTime})'[v${index}];`;
      }
    });

    // Add improved subtitles with black background and white bold font
    const lastVideoOutput = `[v${images.length - 1}]`;
    filterComplex += `${lastVideoOutput}subtitles=${subtitlesPath}:force_style='FontName=Poppins-Bold,FontSize=20,PrimaryColour=&Hffffff,BackColour=&H80000000,Bold=1,Alignment=2'[vout]`;

    command = command
      .complexFilter(filterComplex)
      .outputOptions(["-map", "[vout]", "-map", "1:a"])
      .output(outputPath)
      .on("end", () => {
        logger.info(`‚úì Final video created: ${outputPath}`);
        resolve(outputPath);
      })
      .on("error", (error) => {
        logger.error("Video assembly error:", error);
        reject(error);
      })
      .run();
  });
};

// Combine audio files function
const combineAudioFiles = async (audioFiles, outputPath) => {
  logger.info("‚Üí Preparing audio for video assembly");

  // Check if audioFiles is the new single-file format
  if (audioFiles && audioFiles.conversationFile) {
    logger.info(
      `‚Üí Using single conversation file: ${audioFiles.conversationFile}`
    );

    const sourceFile = audioFiles.conversationFile;
    if (fs.existsSync(sourceFile)) {
      fs.copyFileSync(sourceFile, outputPath);
      logger.info(`‚úì Audio file prepared: ${outputPath}`);
      return outputPath;
    } else {
      throw new Error(`Conversation file not found: ${sourceFile}`);
    }
  }

  // Fallback to old format if needed
  if (Array.isArray(audioFiles) && audioFiles.length > 0) {
    logger.info(
      `‚Üí Combining ${audioFiles.length} audio files into ${outputPath}`
    );

    return new Promise((resolve, reject) => {
      let ffmpegCommand = ffmpeg();

      audioFiles.forEach((audioFile) => {
        ffmpegCommand = ffmpegCommand.input(audioFile.file);
      });

      const inputs = audioFiles.map((_, index) => `[${index}:0]`).join("");
      const filterComplex = `${inputs}concat=n=${audioFiles.length}:v=0:a=1[out]`;

      ffmpegCommand
        .complexFilter(filterComplex)
        .outputOptions(["-map", "[out]"])
        .audioCodec("mp3")
        .output(outputPath)
        .on("end", () => {
          logger.info(`‚úì Audio files combined: ${outputPath}`);
          resolve(outputPath);
        })
        .on("error", (error) => {
          logger.error("Audio combination error:", error);
          reject(error);
        })
        .run();
    });
  }

  throw new Error("No valid audio files provided for combination");
};

// Get workflow status
const getWorkflowStatus = (req, res) => {
  res.json(currentWorkflow);
};

module.exports = {
  runWorkflow,
  getWorkflowStatus,
};
